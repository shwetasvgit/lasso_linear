{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12653715",
   "metadata": {},
   "source": [
    "<h3> CS3920/CS5920 Machine Learning Coursework</h3>\n",
    "\n",
    "<h4> Assignment 2</h4>\n",
    "    \n",
    "This Assignment contains implemention of the following :<br>\n",
    "  - Diabetes dataset from scikit learn exploration<br>\n",
    "  - Original diabetes dataset preprocessing and plotting<br>\n",
    "  - Inductive conformal predictor<br>\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2272c9",
   "metadata": {},
   "source": [
    "<h5> TASK 1: Load the scikit-learn version of the diabetes dataset using the load_diabetes function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "227d4593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The features in diabetes dataset are: ['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6']\n"
     ]
    }
   ],
   "source": [
    "#Import dataset from scikit learn\n",
    "import numpy as np\n",
    "np.set_printoptions(suppress=True)\n",
    "from sklearn.datasets import load_diabetes\n",
    "diabetes = load_diabetes()\n",
    "print(\"The features in diabetes dataset are:\" ,diabetes['feature_names'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4d8c52",
   "metadata": {},
   "source": [
    "<h5> TASK 2: Split the dataset into the training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22903472",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(diabetes['data'], diabetes['target'],random_state =1403)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40d44db",
   "metadata": {},
   "source": [
    "<h5> TASK 3 : The training and test R2 for the Lasso model using the default parameters. Number of features and features used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "937f39e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The default train score is 0.38057774122082466\n",
      "The default test score is 0.30695764399889636\n"
     ]
    }
   ],
   "source": [
    "#Running Lasso on the diabetes dataset\n",
    "from sklearn.linear_model import Lasso\n",
    "lasso = Lasso().fit(X_train,y_train)\n",
    "print(\"The default train score is\",lasso.score(X_train,y_train))\n",
    "print(\"The default test score is\" , lasso.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a62dac3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of features used: 2\n",
      "The selected features are: bmi, s5\n"
     ]
    }
   ],
   "source": [
    "#Features used by lasso for cumputation\n",
    "print(\"The number of features used:\" ,np.sum(lasso.coef_ !=0))\n",
    "feature_index = np.where(lasso.coef_!=0)\n",
    "print(\"The selected features are:\",\", \".join([diabetes['feature_names'][x] for x in feature_index[0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d342f76",
   "metadata": {},
   "source": [
    "<h5> TASK 4,5: Load the original diabetes dataset from the web page and split the data into train and test samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b483d069",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import original data\n",
    "X = np.delete(np.genfromtxt(\"E:\\RHUL\\Machine Learning\\diabetes.data\",delimiter ='\\t',usecols = np.arange(10)),(0),axis =0)\n",
    "Y = np.delete(np.genfromtxt(\"E:\\RHUL\\Machine Learning\\diabetes.data\",usecols = 10, delimiter = '\\t', dtype = int),(0),axis=0)\n",
    "X_train_dia, X_test_dia, y_train_dia, y_test_dia = train_test_split(X,Y,random_state=1403)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2541495",
   "metadata": {},
   "source": [
    "<h5>TASK 6 : Lasso model on original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5de6545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The default train score is 0.5155049384574509\n",
      "The default test score is 0.4611292784728689\n"
     ]
    }
   ],
   "source": [
    "#Run lasso on the original data\n",
    "lasso_dia = Lasso().fit(X_train_dia,y_train_dia)\n",
    "print(\"The default train score is\",lasso_dia.score(X_train_dia,y_train_dia))\n",
    "print(\"The default test score is\" , lasso_dia.score(X_test_dia,y_test_dia))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0f8e43b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of features used: 10\n",
      "The selected features are :  age, sex, bmi, bp, s1, s2, s3, s4, s5, s6\n"
     ]
    }
   ],
   "source": [
    "#Coefficients\n",
    "print(\"The number of features used:\" , np.sum(lasso_dia.coef_ !=0))\n",
    "feature_index = np.where(lasso_dia.coef_!=0)\n",
    "print(\"The selected features are : \",\", \".join([diabetes['feature_names'][x] for x in feature_index[0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95000a1c",
   "metadata": {},
   "source": [
    "<h6>Observation</h6>\n",
    "The dataset from sklearn is normalized to 0-1 levels and therefore, lasso results in majority coefficients becoming 0.\n",
    "The original dataset is not normalized and therefore we see the impact of all the features on the final result  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0061b3",
   "metadata": {},
   "source": [
    "<h5>TASK 7,8: Preprocess the training and test sets using StandardScaler and repeat Lasso , note observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fdc58aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score of scaled data 0.5197167357424546\n",
      "Testing score of scaled data 0.4719151389527314\n",
      "The selected labels are :  sex, bmi, bp, s1, s2, s3, s4, s5\n"
     ]
    }
   ],
   "source": [
    "#Standard Scaler from Scikit learn for scaling the data using fit and transform\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "#fitting StandardScaler\n",
    "scaler.fit(X_train_dia)\n",
    "\n",
    "#transform data on StandardScaler\n",
    "X_train_dia_scaled = scaler.transform(X_train_dia)\n",
    "X_test_dia_scaled = scaler.transform(X_test_dia)\n",
    "lasso_norm = Lasso().fit(X_train_dia_scaled,y_train_dia)\n",
    "\n",
    "print(\"Training score of scaled data\",lasso_norm.score(X_train_dia_scaled, y_train_dia))\n",
    "print(\"Testing score of scaled data\",lasso_norm.score(X_test_dia_scaled, y_test_dia))\n",
    "feature_index1 = np.where(lasso_norm.coef_!=0)\n",
    "print(\"The selected labels are : \",\", \".join([diabetes['feature_names'][x] for x in feature_index1[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e37a24a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0., -0., -0., -0.,  0.,  0.,  0.,  0., -0., -0.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Mean of the scaled original data\n",
    "X_train_dia_scaled.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc97dfba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00087257, -0.00144447, -0.00163421, -0.00043523, -0.00074588,\n",
       "       -0.00047613, -0.00048363, -0.00039826, -0.0008797 , -0.00217892])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Mean of the sklearn dataset\n",
    "X_train.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9369dc02",
   "metadata": {},
   "source": [
    "<h5>Observation</h5>\n",
    "The Standard scalar brings down the data to mean = 0 and unit variance, This means the impact of the features are preserved because all the data is centered around 0.\n",
    "where as the sklearn dataset is scaled in such a way that the data shows 2 features have much more impact than the rest of the features\n",
    "Therefore we get better scores in scaled and original data because feautre impacts are conserved and the model trains well\n",
    "\n",
    "When all the features in a data set are important, Lasso tends to omit features and therefore impact of a few significant features on the label\n",
    "might get removed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680be2ec",
   "metadata": {},
   "source": [
    "<h5>TASK 9 : Plot R2 and number of features, and make it pretty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "644b2b47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'R2 vs Number of features')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "lasso_score = []\n",
    "total_coef = []\n",
    "a = 0.1\n",
    "while a<=5:\n",
    "    lasso_alpha = Lasso(alpha=a,max_iter=1000).fit(X_train_dia_scaled,y_train_dia)\n",
    "    lasso_score.append(lasso_alpha.score(X_test_dia_scaled,y_test_dia))\n",
    "    total_coef.append(np.sum(lasso_alpha.coef_ !=0))    \n",
    "    #print(total_coef)\n",
    "    a = a + 0.01\n",
    "plt.plot(total_coef,lasso_score)\n",
    "plt.grid()\n",
    "plt.xlabel(\"Number of features used\")\n",
    "plt.ylabel(\"R2 Scores\")\n",
    "plt.title(\"R2 vs Number of features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ffc2fd",
   "metadata": {},
   "source": [
    "<h5> TASK 10 : Choose the regularization parameter for the Lasso using cross-validation\n",
    "on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25ceea47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The alpha for which we get the best scores:  1.0000000000000007\n",
      "The optimum test score is 0.4719151389527314\n",
      "The optimum train score is 0.5197167357424546\n",
      "The selected features are :  sex, bmi, bp, s1, s2, s3, s4, s5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "best_score = np.NINF\n",
    "b = 0.01\n",
    "#Cross validation\n",
    "while b<=5:\n",
    "    lasso_val = Lasso(alpha=b,max_iter=1000).fit(X_train_dia_scaled,y_train_dia)   \n",
    "    scores = cross_val_score(lasso_val,X_train_dia_scaled,y_train_dia,cv=5)  \n",
    "    score = np.mean(scores)    \n",
    "    b= b + 0.01  \n",
    "    if score > best_score:        \n",
    "        alpha_optimum = b\n",
    "        best_score = score\n",
    "print(\"The alpha for which we get the best scores: \", alpha_optimum)\n",
    "#Apply optimum alpha on Lasso\n",
    "lasso_optimum = Lasso(alpha=alpha_optimum,max_iter=1000).fit(X_train_dia_scaled,y_train_dia)\n",
    "print(\"The optimum test score is\",lasso_optimum.score(X_test_dia_scaled, y_test_dia))\n",
    "print(\"The optimum train score is\",lasso_optimum.score(X_train_dia_scaled, y_train_dia))\n",
    "print(\"The selected features are : \",\", \".join([diabetes['feature_names'][x] for x in np.where(lasso_optimum.coef_!=0)[0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7354e00d",
   "metadata": {},
   "source": [
    "<h5>TASK 11 : Inductive Conformal Prediction on original data with Lasso prediction model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e7321e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of elements in caliberation set (99, 10)\n"
     ]
    }
   ],
   "source": [
    "#Create caliberation set and train proper\n",
    "X_train_pr, X_valid, y_train_pr, y_valid = train_test_split(X_train_dia,\n",
    "y_train_dia, random_state=1403,test_size=99)\n",
    "print(\"The number of elements in caliberation set\",X_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2b2cc0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of elements in test set (111, 10)\n"
     ]
    }
   ],
   "source": [
    "#Pre-processing the data on train proper and transforming training,caliberation and test data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_pr)\n",
    "X_train_pr_scaled = scaler.transform(X_train_pr)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "X_test_scaled = scaler.transform(X_test_dia)\n",
    "print(\"The number of elements in test set\", X_test_scaled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97a4adb",
   "metadata": {},
   "source": [
    "<h6>Lasso Training</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "895f5f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimum alpha calculated from cros-validation 1.350000000000001\n",
      "The score on this alpha 0.4796126246332718\n"
     ]
    }
   ],
   "source": [
    "c = 0.01\n",
    "best_score_conformal = np.NINF\n",
    "\n",
    "#Cross-validation for optimum value of alpha\n",
    "while c<=5:\n",
    "    lasso_model_check = Lasso(alpha=c,max_iter=1000).fit(X_train_pr_scaled,y_train_pr)   \n",
    "    scores_conformal = cross_val_score(lasso_model_check,X_train_pr_scaled,y_train_pr,cv=5)   \n",
    "    score_conformal = np.mean(scores_conformal)      \n",
    "    c= c + 0.01  \n",
    "    if score_conformal > best_score_conformal:        \n",
    "        alpha_optimum_conformal = c\n",
    "        best_score_conformal = score_conformal\n",
    "lasso_model = Lasso(alpha = alpha_optimum_conformal).fit(X_train_pr_scaled,y_train_pr)\n",
    "print(\"The optimum alpha calculated from cros-validation\", alpha_optimum_conformal)\n",
    "print(\"The score on this alpha\",best_score_conformal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4386e0d8",
   "metadata": {},
   "source": [
    "<h6> Inductive conformal implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ab9d7d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test error rate with E = 5% : 0.09009009009009009\n",
      "The test error rat accuracy with E = 20% : 0.18018018018018017\n",
      "\n",
      "The length of interval for E=5% [196.94952524970284, 196.94952524970284, 196.94952524970284, 196.94952524970287, 196.94952524970287, 196.94952524970284, 196.94952524970287, 196.94952524970287, 196.94952524970284, 196.94952524970287, 196.94952524970284, 196.94952524970287, 196.94952524970282, 196.94952524970284, 196.94952524970282, 196.94952524970284, 196.94952524970284, 196.94952524970284, 196.94952524970287, 196.94952524970284, 196.94952524970282, 196.94952524970284, 196.94952524970282, 196.94952524970284, 196.94952524970284, 196.94952524970287, 196.94952524970287, 196.94952524970284, 196.94952524970284, 196.94952524970282, 196.94952524970284, 196.94952524970284, 196.94952524970287, 196.94952524970284, 196.94952524970287, 196.94952524970284, 196.94952524970284, 196.94952524970284, 196.94952524970287, 196.94952524970284, 196.94952524970284, 196.94952524970287, 196.94952524970284, 196.94952524970284, 196.94952524970287, 196.94952524970284, 196.94952524970282, 196.94952524970284, 196.94952524970284, 196.94952524970284, 196.94952524970284, 196.94952524970284, 196.94952524970284, 196.94952524970287, 196.94952524970284, 196.94952524970284, 196.94952524970284, 196.94952524970284, 196.94952524970282, 196.94952524970284, 196.94952524970284, 196.94952524970284, 196.94952524970284, 196.94952524970284, 196.94952524970284, 196.94952524970284, 196.94952524970287, 196.94952524970284, 196.94952524970284, 196.94952524970284, 196.94952524970282, 196.94952524970284, 196.94952524970284, 196.94952524970284, 196.94952524970287, 196.94952524970284, 196.94952524970284, 196.94952524970284, 196.94952524970287, 196.94952524970284, 196.94952524970282, 196.94952524970284, 196.94952524970282, 196.94952524970284, 196.94952524970284, 196.94952524970284, 196.94952524970284, 196.94952524970287, 196.94952524970284, 196.94952524970282, 196.94952524970284, 196.94952524970284, 196.94952524970284, 196.94952524970284, 196.94952524970282, 196.94952524970287, 196.94952524970284, 196.94952524970284, 196.94952524970284, 196.94952524970284, 196.94952524970284, 196.94952524970284, 196.94952524970284, 196.94952524970282, 196.94952524970284, 196.94952524970284, 196.94952524970282, 196.94952524970284, 196.94952524970282, 196.94952524970284, 196.94952524970284]\n",
      "\n",
      "The length of interval for E=20% [151.28219419231647, 151.28219419231647, 151.28219419231647, 151.28219419231644, 151.28219419231647, 151.28219419231647, 151.28219419231644, 151.28219419231647, 151.28219419231647, 151.28219419231644, 151.28219419231647, 151.28219419231644, 151.2821941923165, 151.28219419231647, 151.2821941923165, 151.28219419231647, 151.28219419231647, 151.28219419231647, 151.28219419231647, 151.28219419231647, 151.2821941923165, 151.28219419231647, 151.2821941923165, 151.28219419231647, 151.28219419231647, 151.28219419231647, 151.28219419231644, 151.28219419231647, 151.28219419231647, 151.28219419231647, 151.28219419231647, 151.28219419231647, 151.28219419231644, 151.28219419231647, 151.28219419231644, 151.28219419231647, 151.28219419231647, 151.28219419231647, 151.28219419231647, 151.28219419231647, 151.28219419231647, 151.28219419231644, 151.28219419231647, 151.28219419231647, 151.28219419231644, 151.28219419231647, 151.2821941923165, 151.28219419231647, 151.28219419231647, 151.28219419231647, 151.28219419231647, 151.28219419231647, 151.28219419231647, 151.28219419231644, 151.28219419231647, 151.28219419231647, 151.28219419231647, 151.28219419231647, 151.28219419231647, 151.28219419231647, 151.28219419231647, 151.28219419231647, 151.28219419231647, 151.28219419231647, 151.28219419231647, 151.28219419231647, 151.28219419231644, 151.28219419231647, 151.28219419231647, 151.28219419231647, 151.2821941923165, 151.28219419231647, 151.28219419231647, 151.28219419231647, 151.28219419231644, 151.28219419231647, 151.28219419231647, 151.28219419231647, 151.28219419231644, 151.28219419231647, 151.2821941923165, 151.28219419231647, 151.2821941923165, 151.28219419231647, 151.28219419231647, 151.28219419231647, 151.28219419231647, 151.28219419231644, 151.28219419231647, 151.28219419231647, 151.28219419231647, 151.28219419231647, 151.28219419231647, 151.28219419231647, 151.2821941923165, 151.28219419231644, 151.28219419231647, 151.28219419231647, 151.28219419231647, 151.28219419231647, 151.28219419231647, 151.28219419231647, 151.28219419231647, 151.28219419231647, 151.28219419231647, 151.28219419231647, 151.2821941923165, 151.28219419231647, 151.2821941923165, 151.28219419231647, 151.28219419231647]\n"
     ]
    }
   ],
   "source": [
    "#Import math for ceil function\n",
    "import math\n",
    "y_c1 = [[]]\n",
    "y_c2 = [[]]\n",
    "count_c1 = 0\n",
    "count_c2 = 0\n",
    "amplitude_k5 = []\n",
    "amplitude_k20 = []\n",
    "\n",
    "#prediction of y-hat on caliberation set\n",
    "y_hat_calib_list = lasso_model.predict(X_valid_scaled)\n",
    "# alpha =| y_hat - y |\n",
    "alpha_values = abs(y_hat_calib_list-y_valid)\n",
    "alpha_values.sort()\n",
    "\n",
    "#k = ceil((1-E)*(m+1))\n",
    "k1 = math.ceil((1-0.05)*(len(alpha_values)+1))\n",
    "k2 = math.ceil((1-0.20)*(len(alpha_values)+1))\n",
    "\n",
    "#c = alpha(k)\n",
    "c1 = alpha_values[k1]\n",
    "c2 = alpha_values[k2]\n",
    "\n",
    "#predity y_hat on test set\n",
    "y_hat_test_list = lasso_model.predict(X_test_scaled)\n",
    "\n",
    "#Calculation of prediction intervals \n",
    "for test_sample in range(len(y_hat_test_list)):\n",
    "    y_min_c1 = y_hat_test_list[test_sample] - c1 \n",
    "    y_min_c2 = y_hat_test_list[test_sample] - c2\n",
    "    y_max_c1 = y_hat_test_list[test_sample] + c1 \n",
    "    y_max_c2 = y_hat_test_list[test_sample] + c2\n",
    "    \n",
    "    y_c1.append([y_min_c1,y_max_c1])\n",
    "    y_c2.append([y_min_c2,y_max_c2])\n",
    "    \n",
    "    amplitude_k5.append(abs(y_max_c1-y_min_c1))\n",
    "    amplitude_k20.append(abs(y_max_c2-y_min_c2))\n",
    "    \n",
    "    if y_min_c1 <= y_test[test_sample] <=y_max_c1:\n",
    "        count_c1 = count_c1 +1\n",
    "    if y_min_c2 <= y_test[test_sample] <=y_max_c2:\n",
    "        count_c2 = count_c2 +1 \n",
    "        \n",
    "#Calculation of test error \n",
    "test_error_c1 = (len(y_test_dia) -count_c1) / len(y_test_dia)\n",
    "test_error_c2 = (len(y_test_dia) -count_c2) / len(y_test_dia)\n",
    "\n",
    "print(\"The test error rate with E = 5% :\", test_error_c1)\n",
    "print(\"The test error rat accuracy with E = 20% :\", test_error_c2)\n",
    "\n",
    "print(\"\\nThe length of interval for E=5%\", amplitude_k5)\n",
    "print(\"\\nThe length of interval for E=20%\", amplitude_k20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
